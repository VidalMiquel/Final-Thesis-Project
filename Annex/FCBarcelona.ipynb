{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCBarcelona study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "individualMetricsBarcelonaPath = \"../Data/Team_1/05Stage/Metrics/Raw/Individual/IndividualnetworkMetrics.pkl\"\n",
    "globalMetricsBarcelonaPath = \"../Data/Team_1/05Stage/Metrics/Raw/Global/GlobalnetworkMetrics.pkl\"\n",
    "metadataBarcelonaPath = \"../Data/Team_1/03Stage/finalMetadataBarcelona.csv\"\n",
    "playersBarcelonaPath =  \"../Data/Team_1/04Stage/playersList.pkl\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filePath):\n",
    "    try:\n",
    "        df = pd.read_csv(filePath)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No s'ha trobat el fitxer: {filePath}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"El fitxer estÃ  buit: {filePath}\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error de parseig al fitxer: {filePath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocorregut un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickleFile(file):\n",
    "    try:\n",
    "        with open(file, \"rb\") as f:\n",
    "            deserializedFile = pickle.load(f)\n",
    "        return deserializedFile\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File  not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rawed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = loadPickleFile(individualMetricsBarcelonaPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filtered dict by players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCount(df):\n",
    "    counts = df.notna().sum(axis=1)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfCounts(counts):\n",
    "    countDf = pd.DataFrame(counts, columns=['count'])\n",
    "    return countDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDf(df):\n",
    "    maxCount = df['count'].max()\n",
    "\n",
    "    # Calculate the threshold (1/5 of the maximum count)\n",
    "    threshold = maxCount / 4\n",
    "\n",
    "    # Filter the DataFrame to include only rows where the count is at least the threshold\n",
    "    filteredDf = df[df['count'] >= threshold]\n",
    "    return filteredDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtererdMetricsByPlayers(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            counts = getCount(df)\n",
    "            countDf = dfCounts(counts)\n",
    "            filteredCountDf  = filterDf(countDf)\n",
    "            filteredDf = df.loc[filteredCountDf.index]\n",
    "            a = filteredDf.T.to_dict(orient=\"list\")\n",
    "            concatenated_dict[score] = a\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDict = filtererdMetricsByPlayers(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get normalized dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizatedindividualMetrics(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            dfN = (df - df.min()) / (df.max() - df.min())\n",
    "            dfN.set_index(df.index, inplace=True)\n",
    "            a = dfN.T.to_dict(orient=\"list\")\n",
    "            concatenated_dict[score] = a\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDict = normalizatedindividualMetrics(filteredDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get classified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetrics(data):\n",
    "    dfNoNan = data.fillna(\" \")\n",
    "    dfNoBlank = dfNoNan.replace(\" \", float('NaN'))  # Replace blank spaces with 0\n",
    "    # Calculate mean, standard deviation, and count\n",
    "    meanValues = dfNoBlank.mean(axis=1).round(2)\n",
    "    stdValues = dfNoBlank.std(axis=1).round(2)\n",
    "    countValues = dfNoBlank.count(axis=1)\n",
    "\n",
    "    return meanValues, stdValues, countValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiedMetrics(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            metricsTable = pd.DataFrame()\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            meanValues, stdValues, countValues = calculateMetrics(df)  \n",
    "            meanDropNa = meanValues.dropna(axis=0)\n",
    "            if  not meanDropNa.empty:\n",
    "                classifyValues = pd.cut(np.array(meanDropNa), 5, labels=[\"worst\", \"bad\", \"medium\", \"good\", \"excellent\"]).astype(str)\n",
    "                columnClassifiy = pd.DataFrame({'Class': classifyValues}, index=meanDropNa.index)\n",
    "                metricsTable = pd.concat([metricsTable, meanDropNa.rename('Mean'), stdValues.rename('Std'), countValues.rename('Count'), columnClassifiy], axis=1)\n",
    "                metricsTable.set_index(df.index, inplace=True)\n",
    "                metricsTableDict = metricsTable.T.to_dict(orient=\"list\")\n",
    "                concatenated_dict[score] = metricsTableDict\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiedDict = classifiedMetrics(normalizedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filtered dict by scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterScoresBarcelona(dfScore):\n",
    "    # Convert 'Difference' column to numeric\n",
    "    dfScore['Difference'] = pd.to_numeric(dfScore['Difference'], errors='coerce')\n",
    "\n",
    "    # Group by the 'Score' column and calculate the size of each group\n",
    "    scoreCounts = dfScore.groupby('Score').size()\n",
    "\n",
    "    # Filter the DataFrame by the conditions: 'Difference' <= 3, size of 'Score' > 1, and 'Difference' < 0\n",
    "    filteredDfScore = dfScore[((dfScore['Difference'] < 3) & dfScore['Score'].isin(scoreCounts[scoreCounts > 1].index)) | (dfScore['Difference'] <= 0) | (dfScore[\"Score\"] == \"3_2\") | ((dfScore[\"Score\"] == \"3_0\"))]\n",
    "    filteredDfScore = filteredDfScore[filteredDfScore[\"Score\"]!=\"NF\"]\n",
    "\n",
    "    return filteredDfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtererdMetricsByScore(df, keys):\n",
    "    finalDict = {}\n",
    "    # Iterate over elements in df\n",
    "    for element in df:\n",
    "        concatenatedDict = {}\n",
    "        # Iterate over keys\n",
    "        for key in keys:\n",
    "            # Check if the current element has the key\n",
    "            if str(key) in df[element]:\n",
    "                # Assign the value corresponding to the key in concatenatedDict\n",
    "                concatenatedDict[key] = df[element][str(key)]\n",
    "        # Add concatenatedDict to finalDict under the current element\n",
    "        finalDict[element] = concatenatedDict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataBarcelonaFile = readCSV(metadataBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBarcelonaFiltered = filterScoresBarcelona(metadataBarcelonaFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueScores = dfBarcelonaFiltered[\"Score\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDict = filtererdMetricsByScore(classifiedDict, uniqueScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary as a object.\n",
    "def saveDictToPickle(dictionary, filePath):\n",
    "    try:\n",
    "        with open(filePath, \"wb\") as f:\n",
    "            pickle.dump(dictionary, f)\n",
    "        # print(\"Dictionary saved to\", filePath)\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while saving the dictionary:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictToPickle(finalDict, \"../Data/Team_1/05Stage/Metrics/Filtered/Individual/finalIndividualnetworkMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveIndividualMetrics(finalDict, uniqueScores, folderPath):\n",
    "    for score in uniqueScores:\n",
    "        metricsTable = pd.DataFrame()\n",
    "        elementValues = []\n",
    "        for element in finalDict:\n",
    "            if score in finalDict[element]:\n",
    "                if not element in elementValues:\n",
    "                    elementValues.append(element)\n",
    "                df = pd.DataFrame.from_dict(finalDict[element][score], orient='index')\n",
    "                metricsTable = pd.concat([metricsTable, df], axis=1)\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count', 'Class']], names=[None, None])\n",
    "        metricsTable.columns = multiIndex\n",
    "        metricsTable.fillna(0, inplace=True)\n",
    "        metricsTable.to_pickle(f\"{folderPath}/{score}_individualMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveIndividualMetrics(finalDict, uniqueScores, \"../Data/Team_1/06Stage/Tables/Score/Individual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersList = loadPickleFile(playersBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePlayerMetrics(playersList, finalDict, folderPath):\n",
    "    elementValues = []\n",
    "    for key in playersList.keys():\n",
    "        scoreMetrics = {}\n",
    "        previousMetricsTable = pd.DataFrame()\n",
    "        metricsTable = pd.DataFrame()\n",
    "        for element in finalDict:\n",
    "            if element not in elementValues:\n",
    "                elementValues.append(element)\n",
    "            for score in finalDict[element]:\n",
    "                if score in finalDict[element]:\n",
    "                    allValues = []\n",
    "                    if str(key) in finalDict[element][score].keys():\n",
    "                        values = finalDict[element][score][str(key)]\n",
    "                        if values:           \n",
    "                            # Create or update dictionary entry for the score\n",
    "                            if score not in scoreMetrics:\n",
    "                                scoreMetrics[score] = {'Mean': values[0], 'Std': values[1], 'Count': values[2], 'Class': values[3]}\n",
    "                            else:\n",
    "                                scoreMetrics[score]['Mean'] = values[0]\n",
    "                                scoreMetrics[score]['Std'] = values[1]\n",
    "                                scoreMetrics[score]['Count'] = values[2]\n",
    "                                scoreMetrics[score]['Class'] = values[3]\n",
    "                        else:\n",
    "                            if score not in scoreMetrics:\n",
    "                                scoreMetrics[score] = {'Mean': 0, 'Std': 0, 'Count': 0, 'Class':0}\n",
    "                            else:\n",
    "                                scoreMetrics[score]['Mean'] = 0\n",
    "                                scoreMetrics[score]['Std'] = 0\n",
    "                                scoreMetrics[score]['Count'] = 0\n",
    "                                scoreMetrics[score]['Class'] = 0\n",
    "                    else:\n",
    "                        if score not in scoreMetrics:\n",
    "                            scoreMetrics[score] = {'Mean': 0, 'Std': 0, 'Count': 0, 'Class': 0}\n",
    "                        else:\n",
    "                            scoreMetrics[score]['Mean'] = 0\n",
    "                            scoreMetrics[score]['Std'] = 0\n",
    "                            scoreMetrics[score]['Count'] = 0\n",
    "                            scoreMetrics[score]['Class'] = 0\n",
    "\n",
    "            previousMetricsTable = pd.DataFrame.from_dict(scoreMetrics, orient='index')\n",
    "            metricsTable = pd.concat([metricsTable, previousMetricsTable], axis=1) \n",
    "        metricsTable.columns.name = None\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count','Class']], names=[None, None])\n",
    "        metricsTable.columns = multiIndex\n",
    "        metricsTable.fillna(0, inplace=True)\n",
    "        metricsTable.to_pickle(f\"{folderPath}/{key}_individualMetrics.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlayerMetrics(playersList, finalDict, \"../Data/Team_1/06Stage/Tables/Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalMetricsBarcelonaFile = loadPickleFile(globalMetricsBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredGlobal = filtererdMetricsByScore(globalMetricsBarcelonaFile, uniqueScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictToPickle(finalDict, \"../Data/Team_1/05Stage/Metrics/Filtered/Global/finalGlobalnetworkMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGlobalMetrics(filteredGlobal,path ):\n",
    "    elementValues = []\n",
    "    metricsTable = pd.DataFrame()\n",
    "    for element in filteredGlobal: \n",
    "        if element not in elementValues:\n",
    "            elementValues.append(element)\n",
    "        df = pd.DataFrame.from_dict(filteredGlobal[element], orient='index')\n",
    "        meanValues, stdValues, countValues = calculateMetrics(df)\n",
    "        metricsTable = pd.concat([metricsTable, meanValues.rename('Mean'), stdValues.rename('Std'), countValues.rename('Count')], axis=1)\n",
    "    multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count']], names=[None, None])\n",
    "    metricsTable.columns = multiIndex\n",
    "    metricsTable.fillna(0, inplace=True)\n",
    "    metricsTable.to_pickle(f\"{path}/06Stage/Tables/Score/Global/globalMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveGlobalMetrics(filteredGlobal, \"../Data/Team_1/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphics Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"worst\", \"bad\", \"medium\", \"good\", \"excellent\"]\n",
    "catValues = dict(zip(categories,range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDictByExcellence(finalDict):\n",
    "    resultDict = {}\n",
    "    \n",
    "    for element in finalDict:\n",
    "        concatenatedDict = {}\n",
    "        \n",
    "        for score in finalDict[element]:\n",
    "            df = pd.DataFrame.from_dict(finalDict[element][score], orient=\"index\")\n",
    "            dfFiltered = df[(df[3] == \"excellent\") | (df[3] == \"good\")]\n",
    "            dfFiltered.set_index(dfFiltered.index, inplace=True)\n",
    "            filteredDict = dfFiltered.T.to_dict(orient=\"list\")\n",
    "            concatenatedDict[score] = filteredDict\n",
    "        \n",
    "        resultDict[element] = concatenatedDict\n",
    "    \n",
    "    return resultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToTables(transformedDict, uniqueScores):\n",
    "    processedData = {}\n",
    "    \n",
    "    for score in uniqueScores:\n",
    "        combinedDf = pd.DataFrame()\n",
    "        elementValues = []\n",
    "        \n",
    "        for element in transformedDict:\n",
    "            if score in transformedDict[element]:\n",
    "                if element not in elementValues:\n",
    "                    elementValues.append(element)\n",
    "                df = pd.DataFrame.from_dict(transformedDict[element][score], orient='index')\n",
    "                combinedDf = pd.concat([combinedDf, df], axis=1)\n",
    "        \n",
    "        # Create MultiIndex for the columns\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count', 'Class']], names=[None, None])\n",
    "        combinedDf.columns = multiIndex\n",
    "        combinedDf.fillna(0, inplace=True)\n",
    "        \n",
    "        # Store the processed DataFrame in the dictionary\n",
    "        processedData[score] = combinedDf\n",
    "    \n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformClassColumns(dataframe, catValues):\n",
    "    # Replace 0 with \"worst\"\n",
    "    transformedDf = dataframe.replace(0, \"worst\")\n",
    "    \n",
    "    # Extract the 'Class' columns\n",
    "    classColumns = transformedDf.xs('Class', level=1, axis=1)\n",
    "    \n",
    "    # Map class columns to their corresponding numeric values\n",
    "    mappedClassColumns = classColumns.map(lambda x: catValues.get(x, x))\n",
    "    \n",
    "    return mappedClassColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTopRowsBySum(mappedClassColumns, topN=5):\n",
    "    # Calculate row sums\n",
    "    rowSums = mappedClassColumns.sum(axis=1)\n",
    "    \n",
    "    # Sort row sums and get the top N rows\n",
    "    rowSumsSorted = rowSums.sort_values(ascending=False).head(topN)\n",
    "    \n",
    "    # Filter the DataFrame to include only the top N rows\n",
    "    filteredClassColumns = mappedClassColumns.loc[rowSumsSorted.index]\n",
    "    \n",
    "    return filteredClassColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPolarPlot(df, score):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        fig.add_trace(\n",
    "            go.Scatterpolar(\n",
    "                r=df.iloc[i],\n",
    "                theta=df.columns,\n",
    "                fill='toself',\n",
    "                opacity=0.5,\n",
    "                name=f\"Player-{df.index[i]}\",  # Use player's name if available\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        font_size=13,\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=1.0,\n",
    "            xanchor=\"left\",\n",
    "            x=0.8\n",
    "        ),\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                angle=45,\n",
    "                tickangle=45,\n",
    "                visible=True,\n",
    "                gridwidth=2,\n",
    "                range=[0, max(df.max(numeric_only=True))],  # Adjust range based on data\n",
    "                tickvals=list(range(len(categories))),\n",
    "                ticktext=categories,\n",
    "                tickwidth=10\n",
    "            )\n",
    "        ),\n",
    "        title= f\"Player Variables for {score}\",\n",
    "        height=500,\n",
    "        width=800\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total\n",
    "tableTotal = dictToTables(finalDict, uniqueScores)\n",
    "for score in tableTotal:\n",
    "    tableTotalTrans = transformClassColumns(tableTotal[score], catValues)\n",
    "    tableTotalTransTop5 = filterTopRowsBySum(tableTotalTrans, topN=5)\n",
    "    createPolarPlot(tableTotalTransTop5, score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Players "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulativeValuesPlayer = pd.Series(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulateSums(df):\n",
    "    global cumulativeValuesPlayer\n",
    "\n",
    "    # Calculate the sum for each row\n",
    "    new_sums = df.sum(axis=1)\n",
    "\n",
    "    # Add the sums to the global cumulative_sums Series\n",
    "    cumulativeValuesPlayer = cumulativeValuesPlayer.add(new_sums, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total\n",
    "tableTotal = dictToTables(finalDict, uniqueScores)\n",
    "for score in tableTotal:\n",
    "    tableTotalTrans = transformClassColumns(tableTotal[score], catValues)\n",
    "    #tableTotalTransTop5 = filterTopRowsBySum(tableTotalTrans, topN=5)\n",
    "    accumulateSums(tableTotalTrans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5216     199.0\n",
       "5203     180.0\n",
       "5503     179.0\n",
       "5506     173.0\n",
       "5213     163.0\n",
       "4324     145.0\n",
       "4320     143.0\n",
       "5211     140.0\n",
       "5470     136.0\n",
       "6379     128.0\n",
       "5246     123.0\n",
       "10609     92.0\n",
       "6616      50.0\n",
       "4691      48.0\n",
       "11094     43.0\n",
       "6400      33.0\n",
       "22102     23.0\n",
       "3508      16.0\n",
       "7068      12.0\n",
       "20055      5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortcumulativeValuesPlayer = cumulativeValuesPlayer.sort_values(ascending=False)\n",
    "sortcumulativeValuesPlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
