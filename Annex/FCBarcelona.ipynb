{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCBarcelona study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "individualMetricsBarcelonaPath = \"../Data/Team_1/05Stage/Metrics/Raw/Individual/IndividualnetworkMetrics.pkl\"\n",
    "globalMetricsBarcelonaPath = \"../Data/Team_1/05Stage/Metrics/Raw/Global/GlobalnetworkMetrics.pkl\"\n",
    "metadataBarcelonaPath = \"../Data/Team_1/03Stage/finalMetadataBarcelona.csv\"\n",
    "playersBarcelonaPath =  \"../Data/Team_1/04Stage/playersList.pkl\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filePath):\n",
    "    try:\n",
    "        df = pd.read_csv(filePath)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No s'ha trobat el fitxer: {filePath}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"El fitxer estÃ  buit: {filePath}\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error de parseig al fitxer: {filePath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocorregut un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickleFile(file):\n",
    "    try:\n",
    "        with open(file, \"rb\") as f:\n",
    "            deserializedFile = pickle.load(f)\n",
    "        return deserializedFile\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File  not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rawed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = loadPickleFile(individualMetricsBarcelonaPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filtered dict by players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCount(df):\n",
    "    counts = df.notna().sum(axis=1)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfCounts(counts):\n",
    "    countDf = pd.DataFrame(counts, columns=['count'])\n",
    "    return countDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDf(df):\n",
    "    maxCount = df['count'].max()\n",
    "\n",
    "    # Calculate the threshold (1/5 of the maximum count)\n",
    "    threshold = maxCount / 4\n",
    "\n",
    "    # Filter the DataFrame to include only rows where the count is at least the threshold\n",
    "    filteredDf = df[df['count'] >= threshold]\n",
    "    return filteredDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtererdMetricsByPlayers(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            counts = getCount(df)\n",
    "            countDf = dfCounts(counts)\n",
    "            filteredCountDf  = filterDf(countDf)\n",
    "            filteredDf = df.loc[filteredCountDf.index]\n",
    "            a = filteredDf.T.to_dict(orient=\"list\")\n",
    "            concatenated_dict[score] = a\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDict = filtererdMetricsByPlayers(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get normalized dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizatedMetrics(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            dfN = (df - df.min()) / (df.max() - df.min())\n",
    "            dfN.set_index(df.index, inplace=True)\n",
    "            a = dfN.T.to_dict(orient=\"list\")\n",
    "            concatenated_dict[score] = a\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDict = normalizatedMetrics(filteredDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get classified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetrics(data):\n",
    "    dfNoNan = data.fillna(\" \")\n",
    "    dfNoBlank = dfNoNan.replace(\" \", float('NaN'))  # Replace blank spaces with 0\n",
    "    # Calculate mean, standard deviation, and count\n",
    "    meanValues = dfNoBlank.mean(axis=1).round(2)\n",
    "    stdValues = dfNoBlank.std(axis=1).round(2)\n",
    "    countValues = dfNoBlank.count(axis=1)\n",
    "\n",
    "    return meanValues, stdValues, countValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiedMetrics(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            metricsTable = pd.DataFrame()\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            meanValues, stdValues, countValues = calculateMetrics(df)  \n",
    "            meanDropNa = meanValues.dropna(axis=0)\n",
    "            if  not meanDropNa.empty:\n",
    "                classifyValues = pd.cut(np.array(meanDropNa), 5, labels=[\"worst\", \"bad\", \"medium\", \"good\", \"excellent\"]).astype(str)\n",
    "                columnClassifiy = pd.DataFrame({'Class': classifyValues}, index=meanDropNa.index)\n",
    "                metricsTable = pd.concat([metricsTable, meanDropNa.rename('Mean'), stdValues.rename('Std'), countValues.rename('Count'), columnClassifiy], axis=1)\n",
    "                metricsTable.set_index(df.index, inplace=True)\n",
    "                metricsTableDict = metricsTable.T.to_dict(orient=\"list\")\n",
    "                concatenated_dict[score] = metricsTableDict\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiedDict = classifiedMetrics(normalizedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filtered dict by scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterScoresBarcelona(dfScore):\n",
    "    # Convert 'Difference' column to numeric\n",
    "    dfScore['Difference'] = pd.to_numeric(dfScore['Difference'], errors='coerce')\n",
    "\n",
    "    # Group by the 'Score' column and calculate the size of each group\n",
    "    scoreCounts = dfScore.groupby('Score').size()\n",
    "\n",
    "    # Filter the DataFrame by the conditions: 'Difference' <= 3, size of 'Score' > 1, and 'Difference' < 0\n",
    "    filteredDfScore = dfScore[((dfScore['Difference'] < 3) & dfScore['Score'].isin(scoreCounts[scoreCounts > 1].index)) | (dfScore['Difference'] <= 0) | (dfScore[\"Score\"] == \"3_2\") | ((dfScore[\"Score\"] == \"3_0\"))]\n",
    "    filteredDfScore = filteredDfScore[filteredDfScore[\"Score\"]!=\"NF\"]\n",
    "\n",
    "    return filteredDfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtererdMetricsByScore(df, keys):\n",
    "    finalDict = {}\n",
    "    # Iterate over elements in df\n",
    "    for element in df:\n",
    "        concatenatedDict = {}\n",
    "        # Iterate over keys\n",
    "        for key in keys:\n",
    "            # Check if the current element has the key\n",
    "            if str(key) in df[element]:\n",
    "                # Assign the value corresponding to the key in concatenatedDict\n",
    "                concatenatedDict[key] = df[element][str(key)]\n",
    "        # Add concatenatedDict to finalDict under the current element\n",
    "        finalDict[element] = concatenatedDict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataBarcelonaFile = readCSV(metadataBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBarcelonaFiltered = filterScoresBarcelona(metadataBarcelonaFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueScores = dfBarcelonaFiltered[\"Score\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDict = filtererdMetricsByScore(classifiedDict, uniqueScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary as a object.\n",
    "def saveDictToPickle(dictionary, filePath):\n",
    "    try:\n",
    "        with open(filePath, \"wb\") as f:\n",
    "            pickle.dump(dictionary, f)\n",
    "        # print(\"Dictionary saved to\", filePath)\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while saving the dictionary:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictToPickle(finalDict, \"../Data/Team_1/05Stage/Metrics/Filtered/Individual/finalIndividualnetworkMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveIndividualMetrics(finalDict, uniqueScores, folderPath):\n",
    "    for score in uniqueScores:\n",
    "        metricsTable = pd.DataFrame()\n",
    "        elementValues = []\n",
    "        for element in finalDict:\n",
    "            if score in finalDict[element]:\n",
    "                if not element in elementValues:\n",
    "                    elementValues.append(element)\n",
    "                df = pd.DataFrame.from_dict(finalDict[element][score], orient='index')\n",
    "                metricsTable = pd.concat([metricsTable, df], axis=1)\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count', 'Class']], names=[None, None])\n",
    "        metricsTable.columns = multiIndex\n",
    "        metricsTable.fillna(0, inplace=True)\n",
    "        metricsTable.to_pickle(f\"{folderPath}/{score}_individualMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveIndividualMetrics(finalDict, uniqueScores, \"../Data/Team_1/06Stage/Tables/Score/Individual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersList = loadPickleFile(playersBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePlayerMetrics(playersList, finalDict, folderPath):\n",
    "    elementValues = []\n",
    "    for key in playersList.keys():\n",
    "        scoreMetrics = {}\n",
    "        previousMetricsTable = pd.DataFrame()\n",
    "        metricsTable = pd.DataFrame()\n",
    "        for element in finalDict:\n",
    "            if element not in elementValues:\n",
    "                elementValues.append(element)\n",
    "            for score in finalDict[element]:\n",
    "                if score in finalDict[element]:\n",
    "                    allValues = []\n",
    "                    if str(key) in finalDict[element][score].keys():\n",
    "                        values = finalDict[element][score][str(key)]\n",
    "                        if values:           \n",
    "                            # Create or update dictionary entry for the score\n",
    "                            if score not in scoreMetrics:\n",
    "                                scoreMetrics[score] = {'Mean': values[0], 'Std': values[1], 'Count': values[2], 'Class': values[3]}\n",
    "                            else:\n",
    "                                scoreMetrics[score]['Mean'] = values[0]\n",
    "                                scoreMetrics[score]['Std'] = values[1]\n",
    "                                scoreMetrics[score]['Count'] = values[2]\n",
    "                                scoreMetrics[score]['Class'] = values[3]\n",
    "                        else:\n",
    "                            if score not in scoreMetrics:\n",
    "                                scoreMetrics[score] = {'Mean': 0, 'Std': 0, 'Count': 0, 'Class':0}\n",
    "                            else:\n",
    "                                scoreMetrics[score]['Mean'] = 0\n",
    "                                scoreMetrics[score]['Std'] = 0\n",
    "                                scoreMetrics[score]['Count'] = 0\n",
    "                                scoreMetrics[score]['Class'] = 0\n",
    "                    else:\n",
    "                        if score not in scoreMetrics:\n",
    "                            scoreMetrics[score] = {'Mean': 0, 'Std': 0, 'Count': 0, 'Class': 0}\n",
    "                        else:\n",
    "                            scoreMetrics[score]['Mean'] = 0\n",
    "                            scoreMetrics[score]['Std'] = 0\n",
    "                            scoreMetrics[score]['Count'] = 0\n",
    "                            scoreMetrics[score]['Class'] = 0\n",
    "\n",
    "            previousMetricsTable = pd.DataFrame.from_dict(scoreMetrics, orient='index')\n",
    "            metricsTable = pd.concat([metricsTable, previousMetricsTable], axis=1) \n",
    "        metricsTable.columns.name = None\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count','Class']], names=[None, None])\n",
    "        metricsTable.columns = multiIndex\n",
    "        metricsTable.fillna(0, inplace=True)\n",
    "        metricsTable.to_pickle(f\"{folderPath}/{key}_individualMetrics.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlayerMetrics(playersList, finalDict, \"../Data/Team_1/06Stage/Tables/Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalMetricsBarcelonaFile = loadPickleFile(globalMetricsBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(globalMetricsBarcelonaFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredGlobal = filtererdMetricsByScore(globalMetricsBarcelonaFile, uniqueScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictToPickle(finalDict, \"../Data/Team_1/05Stage/Metrics/Filtered/Global/finalGlobalnetworkMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGlobalMetrics(filteredGlobal,path ):\n",
    "    elementValues = []\n",
    "    metricsTable = pd.DataFrame()\n",
    "    for element in filteredGlobal: \n",
    "        if element not in elementValues:\n",
    "            elementValues.append(element)\n",
    "        df = pd.DataFrame.from_dict(filteredGlobal[element], orient='index')\n",
    "        meanValues, stdValues, countValues = calculateMetrics(df)\n",
    "        metricsTable = pd.concat([metricsTable, meanValues.rename('Mean'), stdValues.rename('Std'), countValues.rename('Count')], axis=1)\n",
    "    multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count']], names=[None, None])\n",
    "    metricsTable.columns = multiIndex\n",
    "    metricsTable.fillna(0, inplace=True)\n",
    "    metricsTable.to_pickle(f\"{path}/06Stage/Tables/Score/Global/globalMetrics.pkl\")\n",
    "    return metricsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveGlobalMetrics(filteredGlobal, \"../Data/Team_1/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
