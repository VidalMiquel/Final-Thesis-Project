{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCBarcelona study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "individualMetricsBarcelonaPath = \"../Data/Team_1/05Stage/Metrics/Raw/Individual/IndividualnetworkMetrics.pkl\"\n",
    "globalMetricsBarcelonaPath = \"../Data/Team_1/05Stage/Metrics/Raw/Global/GlobalnetworkMetrics.pkl\"\n",
    "metadataBarcelonaPath = \"../Data/Team_1/03Stage/finalMetadataBarcelona.csv\"\n",
    "playersBarcelonaPath =  \"../Data/Team_1/04Stage/playersList.pkl\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(filePath):\n",
    "    try:\n",
    "        df = pd.read_csv(filePath)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No s'ha trobat el fitxer: {filePath}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"El fitxer estÃ  buit: {filePath}\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error de parseig al fitxer: {filePath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocorregut un error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickleFile(file):\n",
    "    try:\n",
    "        with open(file, \"rb\") as f:\n",
    "            deserializedFile = pickle.load(f)\n",
    "        return deserializedFile\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File  not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rawed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = loadPickleFile(individualMetricsBarcelonaPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filtered dict by players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCount(df):\n",
    "    counts = df.notna().sum(axis=1)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfCounts(counts):\n",
    "    countDf = pd.DataFrame(counts, columns=['count'])\n",
    "    return countDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDf(df):\n",
    "    maxCount = df['count'].max()\n",
    "\n",
    "    # Calculate the threshold (1/5 of the maximum count)\n",
    "    threshold = maxCount / 4\n",
    "\n",
    "    # Filter the DataFrame to include only rows where the count is at least the threshold\n",
    "    filteredDf = df[df['count'] >= threshold]\n",
    "    return filteredDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtererdMetricsByPlayers(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            counts = getCount(df)\n",
    "            countDf = dfCounts(counts)\n",
    "            filteredCountDf  = filterDf(countDf)\n",
    "            filteredDf = df.loc[filteredCountDf.index]\n",
    "            a = filteredDf.T.to_dict(orient=\"list\")\n",
    "            concatenated_dict[score] = a\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDict = filtererdMetricsByPlayers(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get normalized dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizatedMetrics(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            dfN = (df - df.min()) / (df.max() - df.min())\n",
    "            dfN.set_index(df.index, inplace=True)\n",
    "            a = dfN.T.to_dict(orient=\"list\")\n",
    "            concatenated_dict[score] = a\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedDict = normalizatedMetrics(filteredDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get classified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetrics(data):\n",
    "    dfNoNan = data.fillna(\" \")\n",
    "    dfNoBlank = dfNoNan.replace(\" \", float('NaN'))  # Replace blank spaces with 0\n",
    "    # Calculate mean, standard deviation, and count\n",
    "    meanValues = dfNoBlank.mean(axis=1).round(2)\n",
    "    stdValues = dfNoBlank.std(axis=1).round(2)\n",
    "    countValues = dfNoBlank.count(axis=1)\n",
    "\n",
    "    return meanValues, stdValues, countValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiedMetrics(file):\n",
    "    finalDict = {}\n",
    "    for element in file:\n",
    "        concatenated_dict = {}\n",
    "        for score in file[element]:\n",
    "            metricsTable = pd.DataFrame()\n",
    "            df = pd.DataFrame.from_dict(file[element][score], orient=\"index\")\n",
    "            meanValues, stdValues, countValues = calculateMetrics(df)  \n",
    "            meanDropNa = meanValues.dropna(axis=0)\n",
    "            if  not meanDropNa.empty:\n",
    "                classifyValues = pd.cut(np.array(meanDropNa), 5, labels=[\"worst\", \"bad\", \"medium\", \"good\", \"excellent\"]).astype(str)\n",
    "                columnClassifiy = pd.DataFrame({'Class': classifyValues}, index=meanDropNa.index)\n",
    "                metricsTable = pd.concat([metricsTable, meanDropNa.rename('Mean'), stdValues.rename('Std'), countValues.rename('Count'), columnClassifiy], axis=1)\n",
    "                metricsTable.set_index(df.index, inplace=True)\n",
    "                metricsTableDict = metricsTable.T.to_dict(orient=\"list\")\n",
    "                concatenated_dict[score] = metricsTableDict\n",
    "        finalDict[element] = concatenated_dict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiedDict = classifiedMetrics(normalizedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get filtered dict by scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterScoresBarcelona(dfScore):\n",
    "    # Convert 'Difference' column to numeric\n",
    "    dfScore['Difference'] = pd.to_numeric(dfScore['Difference'], errors='coerce')\n",
    "\n",
    "    # Group by the 'Score' column and calculate the size of each group\n",
    "    scoreCounts = dfScore.groupby('Score').size()\n",
    "\n",
    "    # Filter the DataFrame by the conditions: 'Difference' <= 3, size of 'Score' > 1, and 'Difference' < 0\n",
    "    filteredDfScore = dfScore[((dfScore['Difference'] < 3) & dfScore['Score'].isin(scoreCounts[scoreCounts > 1].index)) | (dfScore['Difference'] <= 0) | (dfScore[\"Score\"] == \"3_2\") | ((dfScore[\"Score\"] == \"3_0\"))]\n",
    "    filteredDfScore = filteredDfScore[filteredDfScore[\"Score\"]!=\"NF\"]\n",
    "\n",
    "    return filteredDfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtererdMetricsByScore(df, keys):\n",
    "    finalDict = {}\n",
    "    # Iterate over elements in df\n",
    "    for element in df:\n",
    "        concatenatedDict = {}\n",
    "        # Iterate over keys\n",
    "        for key in keys:\n",
    "            # Check if the current element has the key\n",
    "            if str(key) in df[element]:\n",
    "                # Assign the value corresponding to the key in concatenatedDict\n",
    "                concatenatedDict[key] = df[element][str(key)]\n",
    "        # Add concatenatedDict to finalDict under the current element\n",
    "        finalDict[element] = concatenatedDict\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadataBarcelonaFile = readCSV(metadataBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBarcelonaFiltered = filterScoresBarcelona(metadataBarcelonaFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueScores = dfBarcelonaFiltered[\"Score\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDict = filtererdMetricsByScore(classifiedDict, uniqueScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary as a object.\n",
    "def saveDictToPickle(dictionary, filePath):\n",
    "    try:\n",
    "        with open(filePath, \"wb\") as f:\n",
    "            pickle.dump(dictionary, f)\n",
    "        # print(\"Dictionary saved to\", filePath)\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while saving the dictionary:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictToPickle(finalDict, \"../Data/Team_1/05Stage/Metrics/Filtered/Individual/finalIndividualnetworkMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveIndividualMetrics(finalDict, uniqueScores, folderPath):\n",
    "    for score in uniqueScores:\n",
    "        metricsTable = pd.DataFrame()\n",
    "        elementValues = []\n",
    "        for element in finalDict:\n",
    "            if score in finalDict[element]:\n",
    "                if not element in elementValues:\n",
    "                    elementValues.append(element)\n",
    "                df = pd.DataFrame.from_dict(finalDict[element][score], orient='index')\n",
    "                metricsTable = pd.concat([metricsTable, df], axis=1)\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count', 'Class']], names=[None, None])\n",
    "        metricsTable.columns = multiIndex\n",
    "        metricsTable.fillna(0, inplace=True)\n",
    "        metricsTable.to_pickle(f\"{folderPath}/{score}_individualMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveIndividualMetrics(finalDict, uniqueScores, \"../Data/Team_1/06Stage/Tables/Score/Individual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersList = loadPickleFile(playersBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePlayerMetrics(playersList, finalDict, folderPath):\n",
    "    elementValues = []\n",
    "    for key in playersList.keys():\n",
    "        scoreMetrics = {}\n",
    "        previousMetricsTable = pd.DataFrame()\n",
    "        metricsTable = pd.DataFrame()\n",
    "        for element in finalDict:\n",
    "            if element not in elementValues:\n",
    "                elementValues.append(element)\n",
    "            for score in finalDict[element]:\n",
    "                if score in finalDict[element]:\n",
    "                    allValues = []\n",
    "                    if str(key) in finalDict[element][score].keys():\n",
    "                        values = finalDict[element][score][str(key)]\n",
    "                        if values:           \n",
    "                            # Create or update dictionary entry for the score\n",
    "                            if score not in scoreMetrics:\n",
    "                                scoreMetrics[score] = {'Mean': values[0], 'Std': values[1], 'Count': values[2], 'Class': values[3]}\n",
    "                            else:\n",
    "                                scoreMetrics[score]['Mean'] = values[0]\n",
    "                                scoreMetrics[score]['Std'] = values[1]\n",
    "                                scoreMetrics[score]['Count'] = values[2]\n",
    "                                scoreMetrics[score]['Class'] = values[3]\n",
    "                        else:\n",
    "                            if score not in scoreMetrics:\n",
    "                                scoreMetrics[score] = {'Mean': 0, 'Std': 0, 'Count': 0, 'Class':0}\n",
    "                            else:\n",
    "                                scoreMetrics[score]['Mean'] = 0\n",
    "                                scoreMetrics[score]['Std'] = 0\n",
    "                                scoreMetrics[score]['Count'] = 0\n",
    "                                scoreMetrics[score]['Class'] = 0\n",
    "                    else:\n",
    "                        if score not in scoreMetrics:\n",
    "                            scoreMetrics[score] = {'Mean': 0, 'Std': 0, 'Count': 0, 'Class': 0}\n",
    "                        else:\n",
    "                            scoreMetrics[score]['Mean'] = 0\n",
    "                            scoreMetrics[score]['Std'] = 0\n",
    "                            scoreMetrics[score]['Count'] = 0\n",
    "                            scoreMetrics[score]['Class'] = 0\n",
    "\n",
    "            previousMetricsTable = pd.DataFrame.from_dict(scoreMetrics, orient='index')\n",
    "            metricsTable = pd.concat([metricsTable, previousMetricsTable], axis=1) \n",
    "        metricsTable.columns.name = None\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count','Class']], names=[None, None])\n",
    "        metricsTable.columns = multiIndex\n",
    "        metricsTable.fillna(0, inplace=True)\n",
    "        metricsTable.to_pickle(f\"{folderPath}/{key}_individualMetrics.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePlayerMetrics(playersList, finalDict, \"../Data/Team_1/06Stage/Tables/Player\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalMetricsBarcelonaFile = loadPickleFile(globalMetricsBarcelonaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredGlobal = filtererdMetricsByScore(globalMetricsBarcelonaFile, uniqueScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDictToPickle(finalDict, \"../Data/Team_1/05Stage/Metrics/Filtered/Global/finalGlobalnetworkMetrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGlobalMetrics(filteredGlobal,path ):\n",
    "    elementValues = []\n",
    "    metricsTable = pd.DataFrame()\n",
    "    for element in filteredGlobal: \n",
    "        if element not in elementValues:\n",
    "            elementValues.append(element)\n",
    "        df = pd.DataFrame.from_dict(filteredGlobal[element], orient='index')\n",
    "        meanValues, stdValues, countValues = calculateMetrics(df)\n",
    "        metricsTable = pd.concat([metricsTable, meanValues.rename('Mean'), stdValues.rename('Std'), countValues.rename('Count')], axis=1)\n",
    "    multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count']], names=[None, None])\n",
    "    metricsTable.columns = multiIndex\n",
    "    metricsTable.fillna(0, inplace=True)\n",
    "    metricsTable.to_pickle(f\"{path}/06Stage/Tables/Score/Global/globalMetrics.pkl\")\n",
    "    return metricsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">av_clust</th>\n",
       "      <th colspan=\"3\" halign=\"left\">dty</th>\n",
       "      <th colspan=\"3\" halign=\"left\">diam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_1</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.49</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_2</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_2</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>28</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.17</td>\n",
       "      <td>28</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.66</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_0</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.23</td>\n",
       "      <td>20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.17</td>\n",
       "      <td>20</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.09</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_0</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.15</td>\n",
       "      <td>14</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_1</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.19</td>\n",
       "      <td>11</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.16</td>\n",
       "      <td>11</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.15</td>\n",
       "      <td>12</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.13</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_1</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_3</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_2</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    av_clust               dty              diam            \n",
       "        Mean   Std Count  Mean   Std Count  Mean   Std Count\n",
       "0_1     0.60  0.12     9  0.53  0.16     9  2.71  0.49   7.0\n",
       "0_2     0.38  0.27     3  0.35  0.15     3  5.00  0.00   1.0\n",
       "1_2     0.59  0.16     3  0.51  0.17     3  2.50  0.71   2.0\n",
       "1_0     0.64  0.16    28  0.57  0.17    28  2.96  0.66  26.0\n",
       "2_0     0.56  0.23    20  0.53  0.17    20  3.06  1.09  17.0\n",
       "3_0     0.57  0.16    14  0.52  0.15    14  3.23  0.73  13.0\n",
       "1_1     0.46  0.19    11  0.42  0.16    11  3.00  0.58   7.0\n",
       "2_1     0.54  0.17    12  0.48  0.15    12  3.55  1.13  11.0\n",
       "3_1     0.54  0.18     6  0.47  0.20     6  3.00  0.71   5.0\n",
       "0_3     0.62  0.00     1  0.60  0.00     1  3.00  0.00   1.0\n",
       "1_3     0.60  0.00     1  0.52  0.00     1  3.00  0.00   1.0\n",
       "1_4     0.00  0.00     1  0.20  0.00     1  0.00  0.00   0.0\n",
       "2_2     0.34  0.10     2  0.25  0.05     2  0.00  0.00   0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveGlobalMetrics(filteredGlobal, \"../Data/Team_1/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphics Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"worst\", \"bad\", \"medium\", \"good\", \"excellent\"]\n",
    "catValues = dict(zip(categories,range(len(categories))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDictByExcellence(finalDict):\n",
    "    resultDict = {}\n",
    "    \n",
    "    for element in finalDict:\n",
    "        concatenatedDict = {}\n",
    "        \n",
    "        for score in finalDict[element]:\n",
    "            df = pd.DataFrame.from_dict(finalDict[element][score], orient=\"index\")\n",
    "            dfFiltered = df[(df[3] == \"excellent\") | (df[3] == \"good\")]\n",
    "            dfFiltered.set_index(dfFiltered.index, inplace=True)\n",
    "            filteredDict = dfFiltered.T.to_dict(orient=\"list\")\n",
    "            concatenatedDict[score] = filteredDict\n",
    "        \n",
    "        resultDict[element] = concatenatedDict\n",
    "    \n",
    "    return resultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToTables(transformedDict, uniqueScores):\n",
    "    processedData = {}\n",
    "    \n",
    "    for score in uniqueScores:\n",
    "        combinedDf = pd.DataFrame()\n",
    "        elementValues = []\n",
    "        \n",
    "        for element in transformedDict:\n",
    "            if score in transformedDict[element]:\n",
    "                if element not in elementValues:\n",
    "                    elementValues.append(element)\n",
    "                df = pd.DataFrame.from_dict(transformedDict[element][score], orient='index')\n",
    "                combinedDf = pd.concat([combinedDf, df], axis=1)\n",
    "        \n",
    "        # Create MultiIndex for the columns\n",
    "        multiIndex = pd.MultiIndex.from_product([elementValues, ['Mean', 'Std', 'Count', 'Class']], names=[None, None])\n",
    "        combinedDf.columns = multiIndex\n",
    "        combinedDf.fillna(0, inplace=True)\n",
    "        \n",
    "        # Store the processed DataFrame in the dictionary\n",
    "        processedData[score] = combinedDf\n",
    "    \n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformClassColumns(dataframe, catValues):\n",
    "    # Replace 0 with \"worst\"\n",
    "    transformedDf = dataframe.replace(0, \"worst\")\n",
    "    \n",
    "    # Extract the 'Class' columns\n",
    "    classColumns = transformedDf.xs('Class', level=1, axis=1)\n",
    "    \n",
    "    # Map class columns to their corresponding numeric values\n",
    "    mappedClassColumns = classColumns.map(lambda x: catValues.get(x, x))\n",
    "    \n",
    "    return mappedClassColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTopRowsBySum(mappedClassColumns, topN=5):\n",
    "    # Calculate row sums\n",
    "    rowSums = mappedClassColumns.sum(axis=1)\n",
    "    \n",
    "    # Sort row sums and get the top N rows\n",
    "    rowSumsSorted = rowSums.sort_values(ascending=False).head(topN)\n",
    "    \n",
    "    # Filter the DataFrame to include only the top N rows\n",
    "    filteredClassColumns = mappedClassColumns.loc[rowSumsSorted.index]\n",
    "    \n",
    "    return filteredClassColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPolarPlot(df, score):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        fig.add_trace(\n",
    "            go.Scatterpolar(\n",
    "                r=df.iloc[i],\n",
    "                theta=df.columns,\n",
    "                fill='toself',\n",
    "                opacity=0.5,\n",
    "                name=f\"Player-{df.index[i]}\",  # Use player's name if available\n",
    "                showlegend=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        font_size=13,\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=1.0,\n",
    "            xanchor=\"left\",\n",
    "            x=0.8\n",
    "        ),\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                angle=45,\n",
    "                tickangle=45,\n",
    "                visible=True,\n",
    "                gridwidth=2,\n",
    "                range=[0, max(df.max(numeric_only=True))],  # Adjust range based on data\n",
    "                tickvals=list(range(len(categories))),\n",
    "                ticktext=categories,\n",
    "                tickwidth=10\n",
    "            )\n",
    "        ),\n",
    "        title= f\"Player Variables for {score}\"\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excellence\n",
    "dictExcellence = filterDictByExcellence(finalDict)\n",
    "tableExcellence = dictToTables(dictExcellence, uniqueScores)\n",
    "for score in tableExcellence:\n",
    "    tableExcellenceTrans = transformClassColumns(tableExcellence[score], catValues)\n",
    "    tableExcellenceTransTop5 = filterTopRowsBySum(tableExcellenceTrans, topN=5)\n",
    "    createPolarPlot(tableExcellenceTransTop5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total\n",
    "tableTotal = dictToTables(finalDict, uniqueScores)\n",
    "for score in tableTotal:\n",
    "    tableTotalTrans = transformClassColumns(tableTotal[score], catValues)\n",
    "    tableTotalTransTop5 = filterTopRowsBySum(tableTotalTrans, topN=5)\n",
    "    createPolarPlot(tableTotalTransTop5, score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
